{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b06b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import ruamel.yaml as yaml\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import utils\n",
    "from dataset import create_dataset, create_sampler, create_loader\n",
    "from dataset.utils import collect_tensor_result, grounding_eval_bbox, grounding_eval_bbox_vlue\n",
    "from models.model_bbox import XVLM\n",
    "from models.tokenization_bert import BertTokenizer\n",
    "from models.tokenization_roberta import RobertaTokenizer\n",
    "from optim import create_optimizer\n",
    "from refTools.refer_python3 import REFER\n",
    "from scheduler import create_scheduler\n",
    "from utils.hdfs_io import hmkdir, hcopy, hexists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9561312",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([torch.tensor([33., 14., 0., 1.]), torch.tensor([333., 514., 20., 105.])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox_prompts(image_int, coords, prompts):\n",
    "    # Plot the resulting predictions on top of the original image\n",
    "    plt.figure(figsize=(10,20))\n",
    "    bbox_image = vutils.draw_bounding_boxes(image_int,coords, \n",
    "                                            width=3, \n",
    "                                            labels=[f\"Prompt {i}\" for i in range(len(prompts))],\n",
    "                                            colors=\"red\")\n",
    "\n",
    "    plt.imshow(bbox_image.permute(1,2,0))\n",
    "    plt.xlabel('\\n' + '\\n'.join([f'Prompt {i}: ' + prompts[i] for i in range(len(prompts))]), fontsize=14)\n",
    "    plt.scatter(coords[0][0], coords[0][1], color='blue')\n",
    "    plt.show()\n",
    "    \n",
    "plot_transform = transforms.Compose([\n",
    "    transforms.Resize((config['image_res'], config['image_res']), interpolation=Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.uint8),\n",
    "])\n",
    "\n",
    "plot_transform2 = transforms.Compose([\n",
    "#     transforms.Resize((config['image_res'], config['image_res']), interpolation=Image.BICUBIC),\n",
    "#     transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.ConvertImageDtype(torch.uint8),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d060d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"configs/Grounding_bbox_PascalParts.yaml\"\n",
    "config = yaml.load(open(config_file, 'r'), Loader=yaml.Loader)\n",
    "# checkpoint = \"model_checkpoints/16m_base_finetune/refcoco_bbox/checkpoint_best.pth\"\n",
    "evaluate = False\n",
    "device = 6\n",
    "\n",
    "\n",
    "print(\"Creating dataset\")\n",
    "grd_train_dataset, grd_test_dataset = create_dataset('pascalparts_grounding_bbox', config, evaluate=False)\n",
    "# grd_train_dataset, grd_test_dataset = create_dataset('grounding_bbox', config, evaluate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae05c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_train_dataset.refer.refToAnn[0]['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdde2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grd_train_dataset.refer.Refs[0]\n",
    "grd_train_dataset[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04191aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [grd_test_dataset[i] for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70129570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, text, bbox = grd_test_dataset[7]\n",
    "# plt.imshow(img.permute(1,2,0))\n",
    "# plt.xlabel(text)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "img, caption, bbox = grd_train_dataset[i]\n",
    "\n",
    "# ann = grd_train_dataset.ann[i]\n",
    "# true_bbox = torch.tensor(grd_train_dataset.refer.refToAnn[ann['ref_id']]['bbox'])\n",
    "\n",
    "# bbox.shape\n",
    "image_int = plot_transform(Image.open('./images/coco/train2014/COCO_train2014_000000581857.jpg'))\n",
    "\n",
    "results = bbox.unsqueeze(0)*384\n",
    "cx, cy, w, h = results[:,0], results[:,1], results[:,2], results[:,3]\n",
    "coords = torch.stack((cx - w/2, cy-h/2, cx + w/2, cy + h/2)).T\n",
    "# coords = torch.stack((cx,cy,cx+w, cy + h)).T\n",
    "\n",
    "# print(cx,cy,w,h, cx+w, cy -h)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot_bbox_prompts(image_int, torch.tensor(true_bbox).unsqueeze(0), prompts=[caption])\n",
    "# plot_bbox_prompts(image_int, coords, prompts=[caption])\n",
    "# print(true_bbox)\n",
    "\n",
    "# plt.imshow(img.permute(1,2,0))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_bbox_prompts(plot_transform2(((img - img.min(1, keepdim=True)[0])/img.max(1, keepdim=True)[0]).clip(0,0.99)), coords, prompts=[caption])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_train_dataset.img_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_train_dataset.refer.refToAnn[ann['ref_id']]['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7a908",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # [x['text'] for i,x in enumerate(grd_train_dataset)]\n",
    "# for x in grd_train_dataset:\n",
    "#     print(x)\n",
    "# [x['text'] for x in grd_test_dataset.ann]\n",
    "# grd_test_dataset.ann[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
